{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "600840a4-3f6c-4f96-ac41-1e7dc4ccf2f0",
   "metadata": {},
   "source": [
    "# 捗 Notebook de Comparaﾃｧﾃ｣o de Pipelines de Machine Learning (Diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b061a1",
   "metadata": {},
   "source": [
    "Este notebook tem como objetivo executar dois pipelines (Esteiras A e B) de Machine Learning no mesmo dataset (diabetes.csv), coletar suas mﾃｩtricas de desempenho e comparﾃ｡-las para determinar a abordagem mais eficaz para o problema de classificaﾃｧﾃ｣o."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b7cfe6",
   "metadata": {},
   "source": [
    "## 1. Configuraﾃｧﾃ｣o e Funﾃｧﾃｵes Comuns\n",
    "### 1.1 Instalaﾃｧﾃ｣o e Importaﾃｧﾃ｣o de Bibliotecas\n",
    "Instale todas as dependﾃｪncias necessﾃ｡rias para ambos os pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0ad6da-ed1b-4461-ac01-348aba665cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cﾃｩlula 1.1: Instalaﾃｧﾃ｣o (descomente se necessﾃ｡rio)\n",
    "# !pip install pandas numpy scikit-learn matplotlib seaborn imblearn xgboost kagglehub shap\n",
    "\n",
    "# Cﾃｩlula 1.1: Importaﾃｧﾃｵes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import kagglehub\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "\n",
    "# Scikit-learn e Imblearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import recall_score, f1_score, precision_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Configuraﾃｧﾃ｣o para evitar warnings do SHAP\n",
    "shap.initjs()\n",
    "\n",
    "print(\"Todas as bibliotecas e ferramentas foram importadas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de10160-5149-4a7f-994a-5cbee1d468bd",
   "metadata": {},
   "source": [
    "### 1.2 Funﾃｧﾃｵes Auxiliares Comuns\n",
    "As funﾃｧﾃｵes de traduﾃｧﾃ｣o e carregamento serﾃ｣o centralizadas aqui. O carregamento usarﾃ｡ o mﾃｩtodo do Pipeline A (KaggleHub) para simplificar a obtenﾃｧﾃ｣o dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eced972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cﾃｩlula 1.2: Funﾃｧﾃｵes Auxiliares Comuns\n",
    "\n",
    "DATASET_HANDLE = 'mathchi/diabetes-data-set'\n",
    "TARGET_COL = 'Outcome'\n",
    "DATA_PATH_TEMP = 'temp_data_file.csv' # Nome temporﾃ｡rio do arquivo CSV apﾃｳs download\n",
    "\n",
    "def traduzir_colunas(dados: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''Traduz os nomes das colunas.'''\n",
    "    return dados.rename(columns={\n",
    "        'Pregnancies': 'Gestaﾃｧﾃｵes',\n",
    "        'Glucose': 'Glicose',\n",
    "        'BloodPressure': 'Pressﾃ｣o',\n",
    "        'SkinThickness': 'Espessura da pele',\n",
    "        'Insulin': 'Insulina',\n",
    "        'BMI': 'IMC',\n",
    "        'DiabetesPedigreeFunction': 'Hereditariedade',\n",
    "        'Age': 'Idade',\n",
    "        'Outcome': 'Diagnﾃｳstico'\n",
    "    })\n",
    "\n",
    "def carregar_e_salvar_kaggle(handle: str, save_path: str) -> pd.DataFrame:\n",
    "    '''Carrega o dataset do KaggleHub, salva o CSV localmente e retorna o DataFrame.'''\n",
    "    print(f'Iniciando o carregamento dos dados de: {handle}')\n",
    "    \n",
    "    # Baixar e obter o caminho do arquivo\n",
    "    endereco_de_origem = kagglehub.dataset_download(handle=handle, force_download=True)\n",
    "    diretorio_de_origem = Path(endereco_de_origem).resolve()\n",
    "    \n",
    "    # Encontrar e carregar o CSV\n",
    "    lista_dados_csv = []\n",
    "    for item in diretorio_de_origem.iterdir():\n",
    "        if item.is_file() and item.suffix.lower() == '.csv':\n",
    "            df = pd.read_csv(item)\n",
    "            lista_dados_csv.append(df)\n",
    "            # Salvar em um local conhecido para o Pipeline B usar (se necessﾃ｡rio)\n",
    "            df.to_csv(save_path, index=False)\n",
    "            print(f\"Arquivo CSV salvo temporariamente em '{save_path}'\")\n",
    "            \n",
    "    if not lista_dados_csv:\n",
    "        raise FileNotFoundError(\"Nenhum arquivo CSV encontrado no dataset do Kaggle.\")\n",
    "        \n",
    "    dados = pd.concat(lista_dados_csv, axis=0, ignore_index=True)\n",
    "    print('Finalizando o carregamento dos dados\\n')\n",
    "    return dados\n",
    "\n",
    "# Carregar o dataset para que ambos os pipelines possam utilizﾃ｡-lo\n",
    "dados_originais = carregar_e_salvar_kaggle(DATASET_HANDLE, DATA_PATH_TEMP)\n",
    "print(f\"Shape dos dados carregados: {dados_originais.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6c838a",
   "metadata": {},
   "source": [
    "## 2. Execuﾃｧﾃ｣o do Pipeline A (Modelo MLOps - Baseline)\n",
    "Este pipeline se concentra em uma abordagem robusta de prﾃｩ-processamento (KNN Imputer, RobustScaler) e avaliaﾃｧﾃ｣o de um conjunto diversificado de modelos (RegLog, DT, RF, KNN) com foco no Recall.\n",
    "\n",
    "### 2.1 Funﾃｧﾃｵes Exclusivas do Pipeline A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3e28dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cﾃｩlula 2.1: Funﾃｧﾃｵes Exclusivas do Pipeline A\n",
    "\n",
    "def separar_A(dados: pd.DataFrame, target: str):\n",
    "    '''Separa features e alvo, e divide em treino e teste (80/20 estratificado).'''\n",
    "    X_dados = dados.drop(columns=[target], axis=1)\n",
    "    y_dados = dados[target]\n",
    "    return train_test_split(X_dados, y_dados, test_size=0.2, random_state=42, stratify=y_dados)\n",
    "\n",
    "def imputar_A(X_treino: pd.DataFrame, X_teste: pd.DataFrame):\n",
    "    '''Substitui zeros invﾃ｡lidos por NaN e usa KNNImputer (k=5).'''\n",
    "    print('Iniciando a imputaﾃｧﾃ｣o dos dados (KNN)')\n",
    "    colunas_invalidas = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'Age']\n",
    "    X_treino[colunas_invalidas] = X_treino[colunas_invalidas].replace(0, np.nan)\n",
    "    X_teste[colunas_invalidas] = X_teste[colunas_invalidas].replace(0, np.nan)\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    \n",
    "    # Usando .copy() para garantir que a transformaﾃｧﾃ｣o nﾃ｣o afete o DataFrame original global\n",
    "    X_treino_imputado = pd.DataFrame(imputer.fit_transform(X_treino), columns=X_treino.columns, index=X_treino.index)\n",
    "    X_teste_imputado = pd.DataFrame(imputer.transform(X_teste), columns=X_teste.columns, index=X_teste.index)\n",
    "    \n",
    "    print('Finalizando a imputaﾃｧﾃ｣o dos dados\\n')\n",
    "    return X_treino_imputado, X_teste_imputado\n",
    "\n",
    "def balancear_A(X_treino: pd.DataFrame, y_treino: pd.DataFrame):\n",
    "    '''Equilibra a quantidade de dados por diagnﾃｳstico usando SMOTE.'''\n",
    "    print('Iniciando o balanceamento dos dados (SMOTE)')\n",
    "    X_treino_balanceado, y_treino_balanceado = SMOTE(random_state=42).fit_resample(X_treino, y_treino)\n",
    "    print(f'Finalizando o balanceamento dos dados. Novos positivos: {y_treino_balanceado.sum()}\\n')\n",
    "    return X_treino_balanceado, y_treino_balanceado\n",
    "\n",
    "def padronizar_A(X_treino: pd.DataFrame, X_teste: pd.DataFrame):\n",
    "    '''Aplica padronizaﾃｧﾃ｣o nas colunas usando RobustScaler.'''\n",
    "    print('Iniciando o escalonamento dos dados (RobustScaler)')\n",
    "    scaler = RobustScaler()\n",
    "    X_treino_padronizado = pd.DataFrame(scaler.fit_transform(X_treino), columns=X_treino.columns, index=X_treino.index)\n",
    "    X_teste_padronizado = pd.DataFrame(scaler.transform(X_teste), columns=X_teste.columns, index=X_teste.index)\n",
    "    print('Finalizando o escalonamento dos dados\\n')\n",
    "    return X_treino_padronizado, X_teste_padronizado\n",
    "\n",
    "def criar_modelos_A():\n",
    "    '''Gera uma lista de instﾃ｢ncias de modelos para avaliaﾃｧﾃ｣o.'''\n",
    "    return {\n",
    "        'Logistic Regression (A)': LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42),\n",
    "        'Decision Tree (A)': DecisionTreeClassifier(class_weight='balanced', criterion='entropy', max_depth=4, min_samples_split=10, min_samples_leaf=5, random_state=42),\n",
    "        'KNeighbors (A)': KNeighborsClassifier(n_neighbors=5, weights='distance'),\n",
    "        'Random Forest (A)': RandomForestClassifier(class_weight='balanced', n_estimators=200, random_state=42)\n",
    "    }\n",
    "\n",
    "def avaliar_A(modelos, X_teste, y_teste):\n",
    "    '''Avalia modelos e retorna o de melhor Recall, coletando os resultados.'''\n",
    "    print('Iniciando a avaliaﾃｧﾃ｣o dos modelos do Pipeline A')\n",
    "    resultados = []\n",
    "    \n",
    "    for nome, modelo in modelos.items():\n",
    "        y_previsto = modelo.predict(X_teste)\n",
    "        \n",
    "        resultados.append({\n",
    "            'Pipeline': 'A',\n",
    "            'Modelo': nome,\n",
    "            'Precision': precision_score(y_teste, y_previsto, zero_division=0),\n",
    "            'Recall': recall_score(y_teste, y_previsto, zero_division=0),\n",
    "            'F1-score': f1_score(y_teste, y_previsto, zero_division=0),\n",
    "        })\n",
    "        print(f'\\n--- Classificaﾃｧﾃ｣o do modelo {nome} ---')\n",
    "        print(classification_report(y_teste, y_previsto, zero_division=0))\n",
    "\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "    \n",
    "    melhor_modelo_df = df_resultados.loc[df_resultados['Recall'].idxmax()]\n",
    "    nome_melhor_modelo = melhor_modelo_df['Modelo']\n",
    "    melhor_modelo = modelos[nome_melhor_modelo]\n",
    "    \n",
    "    print(f'\\nMelhor modelo (baseado em Recall): {nome_melhor_modelo}')\n",
    "    return melhor_modelo, df_resultados\n",
    "\n",
    "def treinar_A(modelos, X_treino, y_treino):\n",
    "    '''Treina uma lista de modelos.'''\n",
    "    print('Iniciando o treino dos modelos do Pipeline A')\n",
    "    for modelo in modelos.values():\n",
    "        modelo.fit(X_treino, y_treino)\n",
    "    print('Finalizando o treino dos modelos\\n')\n",
    "    return modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907763f9",
   "metadata": {},
   "source": [
    "### 2.2 Execuﾃｧﾃ｣o do Fluxo A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2591f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cﾃｩlula 2.2: Fluxo Principal do Pipeline A\n",
    "\n",
    "print('=============================================')\n",
    "print('=== EXECUTANDO O PIPELINE A (BASELINE) ===')\n",
    "print('=============================================\\n')\n",
    "\n",
    "dados_A = dados_originais.copy()\n",
    "\n",
    "# 1. Separar Treino/Teste\n",
    "X_treino_A, X_teste_A, y_treino_A, y_teste_A = separar_A(dados_A, TARGET_COL)\n",
    "\n",
    "# 2. Imputaﾃｧﾃ｣o (KNN Imputer)\n",
    "X_treino_imputado_A, X_teste_imputado_A = imputar_A(X_treino_A.copy(), X_teste_A.copy())\n",
    "\n",
    "# 3. Balanceamento (SMOTE)\n",
    "X_treino_base_A, y_treino_base_A = balancear_A(X_treino_imputado_A, y_treino_A)\n",
    "\n",
    "# 4. Padronizaﾃｧﾃ｣o (RobustScaler)\n",
    "X_treino_padronizado_A, X_teste_padronizado_A = padronizar_A(X_treino_base_A, X_teste_imputado_A)\n",
    "feat_names_A = X_treino_padronizado_A.columns.tolist()\n",
    "\n",
    "# 5. Modelagem e Treinamento\n",
    "modelos_A = criar_modelos_A()\n",
    "modelos_treinados_A = treinar_A(modelos_A, X_treino_padronizado_A, y_treino_base_A)\n",
    "\n",
    "# 6. Avaliaﾃｧﾃ｣o e Coleta de Resultados\n",
    "melhor_modelo_A, resultados_A = avaliar_A(modelos_treinados_A, X_teste_padronizado_A, y_teste_A)\n",
    "\n",
    "print('\\n=============================================')\n",
    "print(f'RESULTADOS FINAIS DO PIPELINE A COLETADOS.')\n",
    "print('=============================================\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee08a9f",
   "metadata": {},
   "source": [
    "## 3. Execuﾃｧﾃ｣o do Pipeline B (Otimizado/Deep Dive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5472815",
   "metadata": {},
   "source": [
    "Este pipeline possui prﾃｩ-processamento diferente (remoﾃｧﾃ｣o de colunas, Feature Engineering, SimpleImputer com mediana) e inclui o modelo XGBoost, avaliando as previsﾃｵes com um threshold de $0.3$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f101632d",
   "metadata": {},
   "source": [
    "### 3.1 Funﾃｧﾃｵes Exclusivas do Pipeline B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fc5838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cﾃｩlula 3.1: Funﾃｧﾃｵes Exclusivas do Pipeline B\n",
    "\n",
    "def preprocess_diabetes_data_B(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Prﾃｩ-processamento:\n",
    "    - Remove SkinThickness e Insulin\n",
    "    - Trata zeros em Glucose, BloodPressure, BMI (converte para NaN e imputa mediana)\n",
    "    - Feature engineering: cria variﾃ｡veis de risco\n",
    "    \"\"\"\n",
    "    df = df.copy() \n",
    "    \n",
    "    # 1. Remove colunas\n",
    "    df = df.drop(['SkinThickness', 'Insulin'], axis=1)\n",
    "    \n",
    "    # 2. Trata zeros biologicamente impossﾃｭveis (SimpleImputer Mediana)\n",
    "    cols_to_treat = ['Glucose', 'BloodPressure', 'BMI']\n",
    "    for col in cols_to_treat:\n",
    "        df[col] = df[col].replace(0, np.nan)\n",
    "        \n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    df[cols_to_treat] = imputer.fit_transform(df[cols_to_treat])\n",
    "\n",
    "    # 3. FEATURE ENGINEERING: Variﾃ｡veis de risco\n",
    "    df['idade_maior_45'] = (df['Age'] >= 45).astype(int)\n",
    "    df['imc_obeso'] = (df['BMI'] >= 30).astype(int)\n",
    "    df['idade_bmi'] = df['Age'] * df['BMI']\n",
    "    df['glucose_bmi'] = df['Glucose'] * df['BMI']\n",
    "\n",
    "    # 4. Separa features e target\n",
    "    X = df.drop('Outcome', axis=1)\n",
    "    y = df['Outcome'].values\n",
    "    feat_names = X.columns.tolist()\n",
    "\n",
    "    # 5. Scaling (RobustScaler - Ajustado para o fluxo do notebook)\n",
    "    scaler = RobustScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, columns=feat_names, index=X.index)\n",
    "    \n",
    "    return X_scaled_df, y, feat_names\n",
    "\n",
    "def criar_modelos_B():\n",
    "    '''Cria e retorna dicionﾃ｡rio com modelos de classificaﾃｧﾃ｣o para o Pipeline B.'''\n",
    "    return {\n",
    "        'Logistic Regression (B)': LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000),\n",
    "        'Decision Tree (B)': DecisionTreeClassifier(class_weight='balanced', random_state=42),\n",
    "        'Random Forest (B)': RandomForestClassifier(class_weight='balanced', n_estimators=100, random_state=42),\n",
    "        'XGBoost (B)': xgb.XGBClassifier(scale_pos_weight=1, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "    }\n",
    "\n",
    "def avaliar_B(models, X_test, y_test, threshold=0.3):\n",
    "    \"\"\"\n",
    "    Avalia modelos, aplica threshold de 0.3 e retorna o de melhor Recall, coletando resultados.\n",
    "    \"\"\"\n",
    "    best_recall = -1\n",
    "    best_model_name = None\n",
    "    resultados = []\n",
    "    \n",
    "    print(f\"\\n===== AVALIAﾃﾃグ DE MODELOS DO PIPELINE B (THRESHOLD={threshold}) =====\")\n",
    "\n",
    "    for name, model in models.items():\n",
    "        # Aplica threshold se o modelo suportar predict_proba\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_proba = model.predict_proba(X_test)[:, 1]\n",
    "            y_pred = (y_proba >= threshold).astype(int)\n",
    "        else:\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "        current_recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "        current_f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "        current_precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "        resultados.append({\n",
    "            'Pipeline': 'B',\n",
    "            'Modelo': name,\n",
    "            'Precision': current_precision,\n",
    "            'Recall': current_recall,\n",
    "            'F1-score': current_f1,\n",
    "        })\n",
    "        \n",
    "        # Rastreamento do melhor modelo (Maior Recall)\n",
    "        if current_recall > best_recall:\n",
    "            best_recall = current_recall\n",
    "            best_model_name = name\n",
    "\n",
    "        print(f\"\\n--- {name} ---\")\n",
    "        print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "    melhor_modelo = models[best_model_name]\n",
    "    \n",
    "    print(\"==================================================\")\n",
    "    print(f\"醇 Melhor Modelo Encontrado ({best_model_name})\")\n",
    "    print(f\"  Critﾃｩrio de Seleﾃｧﾃ｣o: Maior Recall\")\n",
    "    print(f\"  Recall (Sensibilidade): {best_recall:.4f}\")\n",
    "    print(\"==================================================\")\n",
    "    \n",
    "    return melhor_modelo, df_resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa6362e",
   "metadata": {},
   "source": [
    "### 3.2 Execuﾃｧﾃ｣o do Fluxo B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e4e9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cﾃｩlula 3.2: Fluxo Principal do Pipeline B\n",
    "\n",
    "print('==================================================')\n",
    "print('=== EXECUTANDO O PIPELINE B (OTIMIZADO/DEEP DIVE) ===')\n",
    "print('==================================================\\n')\n",
    "\n",
    "# 1. Prﾃｩ-processamento e Feature Engineering\n",
    "# Carregar os dados do arquivo temporﾃ｡rio salvo anteriormente\n",
    "dados_B = pd.read_csv(DATA_PATH_TEMP) \n",
    "\n",
    "X_scaled_B, y_B, feat_names_B = preprocess_diabetes_data_B(dados_B)\n",
    "\n",
    "# 2. Split e Balanceamento (SMOTE)\n",
    "X_train_res_B, X_test_B, y_train_res_B, y_test_B = split_and_oversample(\n",
    "    X_scaled_B.values, y_B, test_size=0.2, random_state=42, stratify=True\n",
    ")\n",
    "# Reconverter X_train_res_B para DataFrame para compatibilidade com nomes de features\n",
    "X_train_res_B_df = pd.DataFrame(X_train_res_B, columns=feat_names_B)\n",
    "\n",
    "# 3. Modelagem e Treinamento\n",
    "models_B = criar_modelos_B()\n",
    "models_treinados_B = treinar_A(models_B, X_train_res_B_df, y_train_res_B) # Reutilizando a funﾃｧﾃ｣o de treino A\n",
    "\n",
    "# 4. Avaliaﾃｧﾃ｣o e Coleta de Resultados (com threshold 0.3)\n",
    "melhor_modelo_B, resultados_B = avaliar_B(models_treinados_B, X_test_B, y_test_B, threshold=0.3)\n",
    "\n",
    "print('\\n=============================================')\n",
    "print(f'RESULTADOS FINAIS DO PIPELINE B COLETADOS.')\n",
    "print('=============================================\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d657a00",
   "metadata": {},
   "source": [
    "## 4. Comparaﾃｧﾃ｣o e Interpretaﾃｧﾃ｣o dos Resultados\n",
    "Nesta seﾃｧﾃ｣o, consolidaremos os resultados de ambos os pipelines e visualizaremos as principais diferenﾃｧas em termos de desempenho (mﾃｩtricas) e fatores de influﾃｪncia (importﾃ｢ncia das features).\n",
    "\n",
    "### 4.1 Comparaﾃｧﾃ｣o das Mﾃｩtricas de Desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7140a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cﾃｩlula 4.1: Comparaﾃｧﾃ｣o Consolidada de Mﾃｩtricas\n",
    "\n",
    "# 1. Consolidaﾃｧﾃ｣o\n",
    "resultados_consolidados = pd.concat([resultados_A, resultados_B], ignore_index=True)\n",
    "print(\"--- Tabela Consolidada de Mﾃｩtricas (A vs B) ---\")\n",
    "print(resultados_consolidados)\n",
    "\n",
    "# 2. Grﾃ｡fico de Barras Comparativo (Recall e F1-score)\n",
    "df_plot = resultados_consolidados.melt(id_vars=['Pipeline', 'Modelo'], \n",
    "                                       value_vars=['Recall', 'F1-score'],\n",
    "                                       var_name='Mﾃｩtrica', \n",
    "                                       value_name='Score')\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(x='Modelo', y='Score', hue='Mﾃｩtrica', data=df_plot, \n",
    "            palette={'Recall': 'skyblue', 'F1-score': 'lightcoral'})\n",
    "plt.title('Comparaﾃｧﾃ｣o de Desempenho (Recall e F1-score) por Pipeline e Modelo')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(title='Mﾃｩtrica')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Comparaﾃｧﾃ｣o Direta dos Melhores Modelos\n",
    "melhor_A = resultados_A.loc[resultados_A['Modelo'] == melhor_modelo_A.fit_name] # Ajuste para obter o nome correto\n",
    "melhor_B = resultados_B.loc[resultados_B['Modelo'] == melhor_modelo_B.fit_name]\n",
    "\n",
    "df_melhores = pd.concat([melhor_A, melhor_B], ignore_index=True)\n",
    "\n",
    "print(\"\\n--- Comparaﾃｧﾃ｣o dos Melhores Modelos (Recall Mﾃ｡ximo) ---\")\n",
    "print(df_melhores[['Pipeline', 'Modelo', 'Precision', 'Recall', 'F1-score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e518bb8e",
   "metadata": {},
   "source": [
    "### 4.2 Interpretaﾃｧﾃ｣o Comparativa da Importﾃ｢ncia das Features\n",
    "A comparaﾃｧﾃ｣o aqui ﾃｩ crucial, pois o Pipeline B adicionou novas features e removeu outras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a56595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cﾃｩlula 4.2: Interpretaﾃｧﾃ｣o e Comparaﾃｧﾃ｣o de Features\n",
    "\n",
    "def plot_feature_importances(modelo, X_data, title, ax):\n",
    "    \"\"\"Funﾃｧﾃ｣o auxiliar para plotar a importﾃ｢ncia das features.\"\"\"\n",
    "    if hasattr(modelo, 'feature_importances_'):\n",
    "        importances = modelo.feature_importances_\n",
    "        features = X_data.columns if isinstance(X_data, pd.DataFrame) else [f'Feature {i}' for i in range(X_data.shape[1])]\n",
    "        feature_importance = pd.Series(importances, index=features).sort_values(ascending=True)\n",
    "        feature_importance.plot(kind='barh', ax=ax, title=title, color='teal' if 'B' in title else 'darkorange')\n",
    "        ax.set_xlabel('Importﾃ｢ncia')\n",
    "    else:\n",
    "        ax.set_title(f\"{title}\\n(Modelo sem Feature Importance direta)\")\n",
    "        ax.axis('off')\n",
    "\n",
    "# O modelo mais comum a ser o melhor ﾃｩ o Random Forest nos dois pipelines\n",
    "# Vamos usar o Random Forest de cada um para uma comparaﾃｧﾃ｣o justa de Importﾃ｢ncia das Features.\n",
    "\n",
    "rf_A = modelos_treinados_A['Random Forest (A)']\n",
    "# Usamos o DataFrame padronizado do treino para obter os nomes corretos\n",
    "X_train_RF_A = X_treino_padronizado_A.drop(['Gestaﾃｧﾃｵes', 'Glicose', 'Pressﾃ｣o', 'Espessura da pele', 'Insulina', 'IMC', 'Hereditariedade', 'Idade'], axis=1)\n",
    "X_train_RF_A = X_treino_padronizado_A.copy()\n",
    "\n",
    "\n",
    "rf_B = models_treinados_B['Random Forest (B)']\n",
    "X_train_RF_B = X_train_res_B_df.copy() # DataFrame do treino B jﾃ｡ com as features B\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# 1. Comparaﾃｧﾃ｣o de Importﾃ｢ncia (Usando Random Forest como exemplo)\n",
    "plot_feature_importances(rf_A, X_train_RF_A, 'Importﾃ｢ncia do RF do Pipeline A', axes[0])\n",
    "plot_feature_importances(rf_B, X_train_RF_B, 'Importﾃ｢ncia do RF do Pipeline B', axes[1])\n",
    "\n",
    "plt.suptitle('Comparaﾃｧﾃ｣o da Importﾃ｢ncia das Features (Random Forest)', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "# 2. Interpretaﾃｧﾃ｣o do Melhor Modelo Geral (Se houver uma diferenﾃｧa clara)\n",
    "# Se o melhor modelo for diferente (ex: A=KNN, B=XGBoost), esta cﾃｩlula deve ser ajustada para usar SHAP ou Feature Importance especﾃｭfica.\n",
    "\n",
    "print(\"\\n--- Conclusﾃ｣o da Anﾃ｡lise de Features ---\")\n",
    "print(\"Observe as diferenﾃｧas: O Pipeline B removeu 'SkinThickness' e 'Insulin' e adicionou 'idade_maior_45', 'imc_obeso', 'idade_bmi' e 'glucose_bmi'.\")\n",
    "print(\"A importﾃ｢ncia das features no Pipeline B deve mostrar o impacto destas novas variﾃ｡veis e a ausﾃｪncia das removidas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdf0f5f",
   "metadata": {},
   "source": [
    "### 4.3 Conclusﾃ｣o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c47ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cﾃｩlula 4.3: Conclusﾃ｣o Final\n",
    "\n",
    "print(\"=====================================================\")\n",
    "print(\"========= Sﾃ康TESE FINAL DA COMPARAﾃﾃグ ==========\")\n",
    "print(\"=====================================================\")\n",
    "\n",
    "# Obter o Recall do melhor modelo de cada pipeline\n",
    "recall_A_max = resultados_A['Recall'].max()\n",
    "recall_B_max = resultados_B['Recall'].max()\n",
    "f1_A_max = resultados_A['F1-score'].max()\n",
    "f1_B_max = resultados_B['F1-score'].max()\n",
    "\n",
    "print(f\"\\nMelhor Recall do Pipeline A (Baseline): {recall_A_max:.4f}\")\n",
    "print(f\"Melhor Recall do Pipeline B (Otimizado): {recall_B_max:.4f}\")\n",
    "print(f\"\\nMelhor F1-score do Pipeline A (Baseline): {f1_A_max:.4f}\")\n",
    "print(f\"Melhor F1-score do Pipeline B (Otimizado): {f1_B_max:.4f}\")\n",
    "\n",
    "if recall_B_max > recall_A_max:\n",
    "    diferenca = recall_B_max - recall_A_max\n",
    "    print(f\"\\nCONCLUSﾃグ: O PIPELINE B ﾃｩ superior em Recall, apresentando uma melhoria de {diferenca:.4f} pontos.\")\n",
    "    print(\"Isso sugere que a remoﾃｧﾃ｣o de colunas com ruﾃｭdo (SkinThickness/Insulin), a Feature Engineering e o uso do Threshold 0.3/XGBoost foram eficazes para aumentar a sensibilidade do diagnﾃｳstico.\")\n",
    "elif recall_A_max > recall_B_max:\n",
    "    diferenca = recall_A_max - recall_B_max\n",
    "    print(f\"\\nCONCLUSﾃグ: O PIPELINE A ﾃｩ superior em Recall, apresentando uma melhoria de {diferenca:.4f} pontos.\")\n",
    "    print(\"Isso sugere que a imputaﾃｧﾃ｣o mais complexa (KNN) e a retenﾃｧﾃ｣o das features originais foram mais benﾃｩficas.\")\n",
    "else:\n",
    "    print(\"\\nCONCLUSﾃグ: Os pipelines tﾃｪm desempenho de Recall muito semelhante. A escolha pode depender da complexidade de manutenﾃｧﾃ｣o e tempo de execuﾃｧﾃ｣o.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
